{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before continuing with our model and training, our first job is to preprocess the dataset\n",
    "# This is a very important step in all of machine learning\n",
    "\n",
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images of clearly visible digits\n",
    "# Thus, our preprocessing will be limited to scaling the pixel values, shuffling the data and creating a validation set\n",
    "\n",
    "# NOTE: When finally deploying a model in practice, it might be a good idea to include the prerpocessing as initial layers\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset (including the train and test sets) \n",
    "# - meta info regarding the dataset itself\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our image data (it is recommended to scale the pixel values in the range [0,1] )\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Reshuffling the dataset\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      "Layer (type)                     Output Shape                  Param #     \n",
      "===========================================================================\n",
      "conv2d (Conv2D)                  (None, 24, 24, 50)            1300        \n",
      "___________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)     (None, 12, 12, 50)            0           \n",
      "___________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 10, 10, 50)            22550       \n",
      "___________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 5, 5, 50)              0           \n",
      "___________________________________________________________________________\n",
      "flatten (Flatten)                (None, 1250)                  0           \n",
      "___________________________________________________________________________\n",
      "dense (Dense)                    (None, 10)                    12510       \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function\n",
    "\n",
    "# In general, our model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "# However, when using the softmax activation, the loss can rarely be unstable\n",
    "\n",
    "# Thus, instead of incorporating the softmax into the model itself,\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model with Adam optimizer and the cathegorical crossentropy as a loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',    \n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 18s - loss: 0.2680 - accuracy: 0.9271 - val_loss: 0.0882 - val_accuracy: 0.9737\n",
      "Epoch 2/20\n",
      "422/422 - 18s - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.0692 - val_accuracy: 0.9817\n",
      "Epoch 3/20\n",
      "422/422 - 20s - loss: 0.0528 - accuracy: 0.9841 - val_loss: 0.0374 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      "422/422 - 20s - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.0291 - val_accuracy: 0.9917\n",
      "Epoch 5/20\n",
      "422/422 - 20s - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
      "Epoch 6/20\n",
      "422/422 - 21s - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 7/20\n",
      "422/422 - 20s - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.0241 - val_accuracy: 0.9925\n",
      "Epoch 8/20\n",
      "422/422 - 19s - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0216 - val_accuracy: 0.9928\n",
      "Epoch 9/20\n",
      "422/422 - 20s - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 10/20\n",
      "422/422 - 19s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
      "Epoch 11/20\n",
      "422/422 - 19s - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0077 - val_accuracy: 0.9975\n",
      "Epoch 12/20\n",
      "422/422 - 19s - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0141 - val_accuracy: 0.9947\n",
      "Epoch 13/20\n",
      "422/422 - 19s - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0081 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x279e6bc6e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping], \n",
    "    validation_data = validation_data,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.99 - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0266. Test accuracy: 99.16%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAD/0lEQVR4nO2dzSstcRyH77koTnnJygKrs5KUJEWksJDsRPEPeCn5FxQrWUmytxE2koUSJWEhZYWVLCyQl1Lyeu7mLu7nO93fuefOyPx8Ps/u6Zw551dP0/fMjBmJdDr9Q/Dx86sXIL4GhSdF4UlReFIUnhSFJyXX9WIikdCxnsek0+nE317THk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk+K8TVpES0FBAXhbW5vz/U9PT+Cbm5uRrUV7PCkKT4rCk+LVjM/JyQGfmJgA7+vrc25vZ6Td/uLiAjzTUz/teqyPj4+D9/f3g5eXlzs//+3tDXxvbw+8t7cX/Orqyvl5f6I9nhSFJ0XhSUm45thXP+6ssLAQfGlpCbyjoyPS7xsdHQU/OTkB7+npAa+vrwevra2NdD3ZYn9j6HFnIoDCk6LwpMRqxldUVICvra2BV1dXO7e/vLwEHxoaAm9oaAAfHBwELy0t/ad1RsXBwQH49PQ0+O3tbVaft7W1Ba4ZLwIoPCkKT0qsZvzGxgZ4puvVdqZ3dXWBHx8fO7ff2dkBb2xszLREJ8/Pz+ALCwvgk5OT4Pbcur3+HhbNeBFA4UlReFJidT2+vb0d3P7+eH9/d77/9PT0cxb2m7u7O/DFxUXwqakp8PPz809dTxi0x5Oi8KTE6nDOruXj4wP89fUVPD8/P9T31dTUgI+NjYE/PDyAz83NgZ+dnYX6/s9Gh3MigMKTovCkxGrGz8zMgA8PDzvfPzIyAm5PkT4+PkazME/RjBcBFJ4UhSclVjO+qKgIfHl5GTzTZdrt7W3wzs5O8JeXl/9fnIdoxosACk+KwpMSqxlvKSkpAV9ZWQFvbW11br+/vw/e1NQUybp8QTNeBFB4UhSelFjPeEsymQRfX18Hb25udm4/Pz8Pbq+/f7fjfM14EUDhSVF4Urya8Zbi4mJw+6iUTOf2W1pawHd3d6NZWEzQjBcBFJ4UhSfF6xlvqaurA7fX5+15gNnZWXD7uDPf0YwXARSeFIUnJVa3SYfl8PAQ/P7+HtzO+MrKSnD7SFB7W/Z3Qns8KQpPisKT4tWMz83F5dr71e0jQjM9orS7u9v5/uvr62yX6A3a40lReFIUnhSvztXbGX90dAReVVUV6vPLysrAfZ/xOlcvAig8KV4dztn/vGj/tGpgYAA8Ly8PPJVKga+uroLf3NyEXaI3aI8nReFJUXhSvDqcE9mhwzkRQOFJUXhSFJ4UhSdF4UlReFIUnhSFJ0XhSVF4Upzn6sX3RXs8KQpPisKTovCkKDwpCk/KL7SLIw66TKMCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 502\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (recall that we incorporated the softmaxt activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
