{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Assignment: Implement a Quadratic Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's programming exercise, you will build a custom quadratic layer which computes $y = ax^2 + bx + c$. Similar to the ungraded lab, this layer will be plugged into a model that will be trained on the MNIST dataset. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the quadratic layer (TODO)\n",
    "Implement a simple quadratic layer. It has 3 state variables: $a$, $b$ and $c$. The computation returned is $ax^2 + bx + c$. Make sure it can also accept an activation function.\n",
    "\n",
    "#### `__init__`\n",
    "- call `super(my_fun, self)` to access the base class of `my_fun`, and call the `__init__()` function to initialize that base class.  In this case, `my_fun` is `SimpleQuadratic` and its base class is `Layer`.\n",
    "- self.units: set this using one of the function parameters.\n",
    "- self.activation: The function parameter `activation` will be passed in as a string.  To get the tensorflow object associated with the string, please use `tf.keras.activations.get()` \n",
    "\n",
    "\n",
    "#### `build`\n",
    "The following are suggested steps for writing your code.  If you prefer to use fewer lines to implement it, feel free to do so.  Either way, you'll want to set `self.a`, `self.b` and `self.c`.\n",
    "\n",
    "- a_init: set this to tensorflow's `random_normal_initializer()`\n",
    "- a_init_val: Use the `random_normal_initializer()` that you just created and invoke it, setting the `shape` and `dtype`.\n",
    "    - The `shape` of `a` should have its row dimension equal to the last dimension of `input_shape`, and its column dimension equal to the number of units in the layer.  \n",
    "    - This is because you'll be matrix multiplying x^2 * a, so the dimensions should be compatible.\n",
    "    - set the dtype to 'float32'\n",
    "- self.a: create a tensor using tf.Variable, setting the initial_value and set trainable to True.\n",
    "\n",
    "- b_init, b_init_val, and self.b: these will be set in the same way that you implemented a_init, a_init_val and self.a\n",
    "- c_init: set this to `tf.zeros_initializer`.\n",
    "- c_init_val: Set this by calling the tf.zeros_initializer that you just instantiated, and set the `shape` and `dtype`\n",
    "  - shape: This will be a vector equal to the number of units.  This expects a tuple, and remember that a tuple `(9,)` includes a comma.\n",
    "  - dtype: set to 'float32'.\n",
    "- self.c: create a tensor using tf.Variable, and set the parameters `initial_value` and `trainable`.\n",
    "\n",
    "#### `call`\n",
    "The following section performs the multiplication x^2*a + x*b + c.  The steps are broken down for clarity, but you can also perform this calculation in fewer lines if you prefer.\n",
    "- x_squared: use tf.math.square()\n",
    "- x_squared_times_a: use tf.matmul().  \n",
    "  - If you see an error saying `InvalidArgumentError: Matrix size-incompatible`, please check the order of the matrix multiplication to make sure that the matrix dimensions line up.\n",
    "- x_times_b: use tf.matmul().\n",
    "- x2a_plus_xb_plus_c: add the three terms together.\n",
    "- activated_x2a_plus_xb_plus_c: apply the class's `activation` to the sum of the three terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Ga20PttZFXm4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "687a4c4733c3c581631c2b476104b829",
     "grade": false,
     "grade_id": "cell-c302ddc177c098f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "## You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "class SimpleQuadratic(Layer):\n",
    "\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        '''Initializes the class and sets up the internal variables'''\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        '''Create the state of the layer (weights)'''\n",
    "        # a and b should be initialized with random normal, c (or the bias) with zeros.\n",
    "        # remember to set these as trainable.\n",
    "        a_init = tf.random_normal_initializer()\n",
    "        b_init = tf.random_normal_initializer()\n",
    "        c_init = tf.zeros_initializer()\n",
    "        a_init_val = a_init(shape=(input_shape[-1], self.units), dtype=\"float32\")\n",
    "        b_init_val = b_init(shape=(input_shape[-1], self.units), dtype=\"float32\")\n",
    "        c_init_val = c_init(shape=(self.units, ), dtype=\"float32\")\n",
    "        self.a = tf.Variable(initial_value=a_init_val, trainable=True)\n",
    "        self.b = tf.Variable(initial_value=b_init_val, trainable=True)\n",
    "        self.c = tf.Variable(initial_value=c_init_val, trainable=True)\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        '''Defines the computation from inputs to outputs'''\n",
    "        # Remember to use self.activation() to get the final output\n",
    "        x_squared = tf.math.square(inputs)\n",
    "        x_squared_times_a = tf.linalg.matmul(x_squared, self.a)\n",
    "        x_times_b = tf.linalg.matmul(inputs, self.b)\n",
    "        x2a_plus_xb_plus_c = x_squared_times_a + x_times_b + self.c\n",
    "        return self.activation(x2a_plus_xb_plus_c)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0965bec4878a263cf06b286cd0fe3b2a",
     "grade": true,
     "grade_id": "cell-c3ebc4cccbb7f454",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils.test_simple_quadratic(SimpleQuadratic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now train the model with the `SimpleQuadratic` layer that you just implemented. Please uncomment the cell below to run the training. When you get the expected results, you will need to comment this block again before submitting the notebook to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14tl1CluExjJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.2678 - accuracy: 0.9205\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.1342 - accuracy: 0.9596\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 0.1005 - accuracy: 0.9690\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.0820 - accuracy: 0.9742\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.0708 - accuracy: 0.9772\n",
      "10000/10000 [==============================] - 1s 95us/sample - loss: 0.0824 - accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08240902369013056, 0.9763]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "# # THIS CODE SHOULD RUN WITHOUT MODIFICATION\n",
    "# # AND SHOULD RETURN TRAINING/TESTING ACCURACY at 97%+\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  SimpleQuadratic(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "Before submitting, please make sure to follow these steps to avoid getting timeout issues with the grader:\n",
    "\n",
    "1. Make sure to pass all public tests and get an accuracy greater than 97%.\n",
    "2. Click inside the training code cell above.\n",
    "3. Select all lines in this code cell with `Ctrl+A` (Windows/Linux) or `Cmd+A` (Mac), then press `Ctrl+/` (Windows/Linux) or `Cmd+/` (Mac) to comment the entire block. All lines should turn green as before.\n",
    "4. From the menu bar, click `File > Save and Checkpoint`. *This is important*.\n",
    "5. Once saved, click the `Submit Assignment` button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your work\n",
    "\n",
    "Save your work and click the `Submit` button on the upper right of this lab environment (see the image below for reference). If you don't see it, please try refreshing your browser and check again. If the issue persists, please report it on the [DLAI Forum](https://community.deeplearning.ai/?utm_campaign=forum-engagement&utm_medium=long-form-courses&utm_source=coursera).\n",
    "\n",
    "<img src='submit.png' width=200px>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTFXTWT0EUVuqg6u/LBbJK",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "QuadraticLayer_Answer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
