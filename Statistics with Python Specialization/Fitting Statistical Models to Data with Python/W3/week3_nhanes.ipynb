{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel and marginal modeling, a case study with the NHANES data\n",
    "\n",
    "\n",
    "This notebook is a counterpart to our introductory regression modeling case study for independent data using the [NHANES](https://www.cdc.gov/nchs/nhanes/index.htm) data.  Here we will build on the basic linear and logistic regression approaches discussed in that notebook.  We will be exploring the use of some more advanced regression approaches that can be used for data that are statistically dependent.\n",
    "\n",
    "Note that some of the models illustrated in this notebook may take a few minutes to fit.\n",
    "\n",
    "We begin by importing the libraries that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be *dependent*, or have a *mutilevel structure* for a number of different reasons.  Arguably, most datasets encountered in practice exhibit some form of dependence, and it is independent data, not dependent data, should be treated as the exceptional case. Here we will reconsider the NHANES data from the perspective of dependence, focusing in particular on dependence in the data that arises due to *clustering* which we will define below.\n",
    "\n",
    "First, we read the data from a csv file to a Pandas dataframe, as we have done before.  We remove all rows of data with missing values in the variables of interest (there are more sophisticated approaches for handling missing data that generally will give better results, but for simplicity we do not use them here).\n",
    "\n",
    "Note that in addition to the demographic and health-related variables that we have used before, we also retain two variables here [SDMVSTRA](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#SDMVSTRA) and [SDMVPSU](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#SDMVPSU) that will be used below to define the clustering structure in these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file\n",
    "da = pd.read_csv(\"nhanes_2015_2016.csv\")\n",
    "\n",
    "# Drop unused columns, drop rows with any missing values.\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\",\n",
    "        \"SMQ020\", \"SDMVSTRA\", \"SDMVPSU\"]\n",
    "da = da[vars].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to clustered data\n",
    "\n",
    "One common reason that data are statistically dependent is that the data values were collected as a \"cluster sample\".  This essentially means that the population of interest was first partitioned into groups, then a limited number of these groups were somehow selected, and finally a limited number of individuals were selected from each of the sampled groups. This is the protocol used to collect the NHANES data.  Since NHANES involves physical examinations, it is not practical to select a random sample from the entire US population, as this would involve conducting the examinations at thousands of dispersed locations.  By utilizing cluster sampling, the NHANES staff can set up an examination center in each selected community, and assess many subjects at each center.\n",
    "\n",
    "Cluster sampling is not the only reason that dependence may exist between observations in a dataset.  For example, many studies are *longitudinal*, meaning that each subject is assessed on multiple occasions.  In this setting, we would expect these repeated measurements to be correlated.  Since NHANES is a cluster sample, but is not a longitudinal study, we will focus on cluster sampling here to illustrate multilevel modeling.\n",
    "\n",
    "In any cluster sample, it is likely that observations within the same cluster are more similar than observations in different clusters.  For example, in NHANES the clusters are geographic, and each sample community is somewhat unique in terms of demography, climate, socio-economic status, and lifestyle.  When we have clustered data, it is very importantto account for this statistical dependence in the analysis.\n",
    "\n",
    "## Clustering structure in NHANES\n",
    "\n",
    "The detailed process of collecting data for a study like NHANES is very complex, so we will simplify things here (more\n",
    "details about the NHANES sampling plan can be found [here](https://wwwn.cdc.gov/nchs/nhanes/analyticguidelines.aspx) but are not needed for this course). Roughly speaking, in NHANES the data are collected by selecting a limited number of counties in the US, then selecting subregions of these counties, then selecting people within these subregions.  Since counties are geographically constrained, it is expected that people within a county are more similar to each other than they are to people in other counties.\n",
    "\n",
    "If we could obtain the county identifier where each NHANES participant resides, we could directly incorporate this information into our analysis.  However for privacy reasons this information is not released with the data. Instead, we have access to \"masked variance units\" (MVUs), which are formed by combining subregions of different counties into artificial\n",
    "groups that are not geographically contiguous.  While the MVUs are not the actual clusters of the survey, and are not truly contiguous geographic regions, they are deliberately selected to mimic these things, while minimizing the risk that a subject can be \"unmasked\" in the data.  For the remainder of this notebook, we will treat the MVUs as clusters, and explore the extent to which they induce correlations in some of the NHANES variables that we have been studying.\n",
    "\n",
    "The MVU identifiers can be obtained by combining the `SDMVSTRA` and `SDMVPSU` identifiers, which we do next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"group\"] = 10*da.SDMVSTRA + da.SDMVPSU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intraclass correlation\n",
    "\n",
    "Similarity among observations within a cluster can be measured using a statistic called the [intraclass correlation coefficient](https://en.wikipedia.org/wiki/Intraclass_correlation), or ICC.  This is a distinct form of correlation from the more well-known [Pearson's correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).  The ICC takes on values from 0 to 1, with 1 corresponding to \"perfect clustering\" -- the values within a cluster are identical, and 0 corresponding to \"perfect independence\" -- the mean value within each cluster is identical across all the clusters.\n",
    "\n",
    "We can assess ICC using two regression techniques, *marginal regression*, and *multilevel regression*.  We will start by using a technique called \"Generalized Estimating Equations\" (GEE) to fit marginal linear models, and to estimate the ICC for the NHANES clusters.\n",
    "\n",
    "We will first look at the ICC for systolic blood pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.030\n"
     ]
    }
   ],
   "source": [
    "model = sm.GEE.from_formula(\"BPXSY1 ~ 1\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated ICC is 0.03, which is small but not negligible.\n",
    "Although an ICC is a type of correlation, its values are not directly\n",
    "comparable to Pearson correlation values.  While 0.03 would generally\n",
    "be considered to be very small as a Pearson correlation coefficient,\n",
    "it is not especially small as an ICC.\n",
    "\n",
    "To get a more systematic view of the ICC values induced by clustering\n",
    "in these data, we calculate the ICC for a number of different\n",
    "variables that appear in our analyses, either as outcomes or as\n",
    "predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPXSY1 The correlation between two observations in the same cluster is 0.030\n",
      "RIDAGEYR The correlation between two observations in the same cluster is 0.035\n",
      "BMXBMI The correlation between two observations in the same cluster is 0.039\n",
      "smq The correlation between two observations in the same cluster is 0.026\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.959\n"
     ]
    }
   ],
   "source": [
    "# Recode smoking to a simple binary variable\n",
    "da[\"smq\"] = da.SMQ020.replace({2: 0, 7: np.nan, 9: np.nan})\n",
    "\n",
    "for v in [\"BPXSY1\", \"RIDAGEYR\", \"BMXBMI\", \"smq\", \"SDMVSTRA\"]:\n",
    "    model = sm.GEE.from_formula(v + \" ~ 1\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "    result = model.fit()\n",
    "    print(v, result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are generally similar to what we saw for blood pressure,\n",
    "except for `SDMVSTRA`, which is one component of the cluster\n",
    "definition itself, and therefore has a very high ICC.\n",
    "\n",
    "To illustrate that the ICC values shown above are not consistent with\n",
    "a complete absence of dependence, we simulate 10 sets of random data\n",
    "and calculate the ICC value for each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDMVSTRA The correlation between two observations in the same cluster is -0.001\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.003\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.000\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.000\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.000\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.000\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    da[\"noise\"] = np.random.normal(size=da.shape[0])\n",
    "    model = sm.GEE.from_formula(\"noise ~ 1\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "    result = model.fit()\n",
    "    print(v, result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the estimated ICC for pure simulated noise is random but highly concentrated near zero, varying from around `-0.002` to `+0.002`.  These values are at least a factor of 10 smaller than the ICC values obtaine with the actual NHANES data.  Thus, while the ICC values for the NHANES data are numerically small, they are much larger than what we would expect to obtain if the observations were independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional intraclass correlation\n",
    "\n",
    "The ICC's studied above were *marginal*, in the sense that we were looking at whether, say, the SBP values were more similar within versus between clusters.  To the extent that such \"cluster effects\" are found, it may be largely explained by demographic differences among the clusters.  For example, we know from our previous analyses with the NHANES data that older people have higher SBP than younger people.  Also, some clusters may contain a slightly older or younger set of people than others.  Thus, by controlling for age, we might anticipate that the ICC will become smaller.  This is shown in the next analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.019\n"
     ]
    }
   ],
   "source": [
    "model = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ICC for SBP drops from 0.03 to 0.02.  We can now assess whether it\n",
    "drops even further when we add additional covariates that we know to\n",
    "be predictive of blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.013\n"
     ]
    }
   ],
   "source": [
    "# Create a labeled version of the gender variable\n",
    "da[\"RIAGENDRx\"] = da.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})\n",
    "\n",
    "model = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable\n",
    "[RIDRETH1](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#RIDRETH1)\n",
    "is a categorical variable containing 5 levels of race/ethnicity\n",
    "information.  Since NHANES categorical variables are coded numerically,\n",
    "Statsmodels would have no way of knowing that these are codes and not\n",
    "quantitative data, thus we must use the `C()` syntax in the formula\n",
    "above to force this variable to be treated as being categorical.  We\n",
    "see here that the ICC has further reduced, to 0.013, due to\n",
    "controlling for these additional factors including ethnicity.\n",
    "\n",
    "## Marginal linear models with dependent data\n",
    "\n",
    "Above we focused on quantifying the dependence induced by clustering.\n",
    "By understanding the clustering structure, we have gained additional\n",
    "insight about the data that complements our understanding of the mean\n",
    "structure.  Another facet of working with dependent data is that while\n",
    "the mean structure (i.e. the regression coefficients) can be estimated\n",
    "without considering the dependence structure of the data, the standard\n",
    "errors and other statistics relating to uncertainty will be wrong when\n",
    "we ignore dependence in the data.\n",
    "\n",
    "To illustrate this, below we fit two models with the same mean\n",
    "structure to the NHANES data.  The first is a multiple regression\n",
    "model fit using \"ordinary least squares\" (the default method for\n",
    "independent data).  The second is fit using GEE, which allows us to\n",
    "account for the dependence in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   OLS_params    OLS_SE  GEE_params    GEE_SE\n",
      "Intercept           91.736583  1.339378   92.168530  1.384309\n",
      "RIAGENDRx[T.Male]    3.671294  0.453763    3.650245  0.454498\n",
      "C(RIDRETH1)[T.2]     0.855488  0.819486    0.159296  0.767025\n",
      "C(RIDRETH1)[T.3]    -1.796132  0.671954   -2.233280  0.760228\n",
      "C(RIDRETH1)[T.4]     3.813314  0.732355    3.105654  0.881580\n",
      "C(RIDRETH1)[T.5]    -0.455347  0.808948   -0.439831  0.813675\n",
      "RIDAGEYR             0.478699  0.012901    0.474101  0.018493\n",
      "BMXBMI               0.278015  0.033285    0.280205  0.038553\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear model with OLS\n",
    "model1 = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           data=da)\n",
    "result1 = model1.fit()\n",
    "\n",
    "# Fit a marginal linear model using GEE to handle dependent data\n",
    "model2 = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "result2 = model2.fit()\n",
    "\n",
    "x = pd.DataFrame({\"OLS_params\": result1.params, \"OLS_SE\": result1.bse,\n",
    "                  \"GEE_params\": result2.params, \"GEE_SE\": result2.bse})\n",
    "x = x[[\"OLS_params\", \"OLS_SE\", \"GEE_params\", \"GEE_SE\"]]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, we see that the point estimates are similar\n",
    "between the OLS and GEE fits of the model, but the standard errors\n",
    "tend to be larger in the GEE fit.  For example, the standard errors\n",
    "for BMI and age are 20-40% larger in the GEE fit.  Since we know that\n",
    "there is dependence in these data that is driven by clustering, the\n",
    "OLS approach is not theoretically justified (the OLS parameter\n",
    "estimates remain in meaningful, but the standard errors do not).  GEE\n",
    "parameter estimates and standard errors are meaningful in the presence\n",
    "of dependence, as long as the dependence is exclusively between\n",
    "observations within the same cluster.\n",
    "\n",
    "## Marginal logistic regression with dependent data\n",
    "\n",
    "Above we used GEE to fit marginal linear models in the presence of\n",
    "dependence.  GEE can also be used to fit any GLM in the presence of\n",
    "dependence.  We illustrate this using models relating smoking history\n",
    "to several demographic predictor variables.  These are the same models\n",
    "we fit in our previous notebook using GLM, which ignores the\n",
    "clustering.  Below we fit this same GLM again for comparison, then we\n",
    "fit the marginal model using GEE.  One thing to emphasize in doing\n",
    "this is that the GLM and GEE are both legitimate estimators of the\n",
    "marginal mean structure here.  However GLM will not give correct\n",
    "standard errors, so everything derived from standard errors\n",
    "(e.g. confidence intervals and hypothesis tests) will not be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS_params    OLS_SE  GEE_params    GEE_SE\n",
      "Intercept                     -2.305999  0.114308   -2.249820  0.140567\n",
      "RIAGENDRx[T.Male]              0.909597  0.060167    0.908682  0.062342\n",
      "C(DMDEDUC2x)[T.HS]             0.943364  0.089663    0.887965  0.095397\n",
      "C(DMDEDUC2x)[T.SomeCollege]    0.832227  0.084361    0.771636  0.104449\n",
      "C(DMDEDUC2x)[T.lt9]            0.266228  0.109183    0.321784  0.141327\n",
      "C(DMDEDUC2x)[T.x9_11]          1.098561  0.106697    1.062149  0.138401\n",
      "RIDAGEYR                       0.018257  0.001725    0.017416  0.001803\n"
     ]
    }
   ],
   "source": [
    "# Relabel the levels, convert rare categories to missing.\n",
    "da[\"DMDEDUC2x\"] = da.DMDEDUC2.replace({1: \"lt9\", 2: \"x9_11\", 3: \"HS\", 4: \"SomeCollege\",\n",
    "                                       5: \"College\", 7: np.nan, 9: np.nan})\n",
    "\n",
    "# Fit a basic GLM\n",
    "model1 = sm.GLM.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx + C(DMDEDUC2x)\",\n",
    "           family=sm.families.Binomial(), data=da)\n",
    "result1 = model1.fit()\n",
    "result1.summary()\n",
    "\n",
    "# Fit a marginal GLM using GEE\n",
    "model2 = sm.GEE.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx + C(DMDEDUC2x)\",\n",
    "           groups=\"group\", family=sm.families.Binomial(),\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "result2 = model2.fit(start_params=result1.params)\n",
    "\n",
    "x = pd.DataFrame({\"OLS_params\": result1.params, \"OLS_SE\": result1.bse,\n",
    "                  \"GEE_params\": result2.params, \"GEE_SE\": result2.bse})\n",
    "x = x[[\"OLS_params\", \"OLS_SE\", \"GEE_params\", \"GEE_SE\"]]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the results show that the GLM and the GEE give very\n",
    "similar estimates for the regression parameters.  However the standard\n",
    "errors obtained using GEE are somewhat larger than those obtained\n",
    "using GLM.  This indicates that GLM understates the uncertainty in the\n",
    "estimated mean structure, which is a direct consequence of it ignoring\n",
    "the dependence structure.  The GEE results do not suffer from this\n",
    "weakness.\n",
    "\n",
    "To the extent that the GLM and GEE parameter estimates differ, this is\n",
    "due to GEE attempting to exploit the dependence structure to obtain\n",
    "more efficient (i.e. more accurate) estimates of the model parameters.\n",
    "Thus, in summary, we can view GEE as trying to accomplish three things\n",
    "above and beyond what we obtain from GLM:\n",
    "\n",
    "* GEE gives us insight into the dependence structure of the data\n",
    "\n",
    "* GEE uses the dependence structure to obtain meaningful standard errors of\n",
    "the estimated model parameters.\n",
    "\n",
    "* GEE uses the dependence structure to estimate the model parameters more accurately\n",
    "\n",
    "In contrast, GLM does not achieve the first point at all, and in terms of\n",
    "the second point, the GLM standard errors can be far\n",
    "too optimistic (i.e. too small) -- note that in the analysis we are pursuing\n",
    "here, even weak clustering (ICC around 0.02-0.04) modifies some of the standard errors\n",
    "by 10-40%.  Finally, with regard to the third  point, GEE should\n",
    "in general have an efficiency advantage over GLM, but GLM estimates\n",
    "remain \"valid\" and cannot be completely dismissed solely on this\n",
    "basis.\n",
    "\n",
    "## Multilevel models\n",
    "\n",
    "Multilevel modeling is a large topic, and some aspects of it are quite\n",
    "advanced.  Here, we will explore one facet of multilevel modeling --\n",
    "using it as an alternative way to accommodate dependence in clustered data.  In\n",
    "this sense, multilevel modeling is an alternative to the marginal\n",
    "regression analysis demonstrated above.\n",
    "\n",
    "In the setting of linear regression, mutilevel models and marginal\n",
    "models are similar in most ways (note that more substantial differences\n",
    "between marginal and multilevel models emerge in the case of logistic\n",
    "regression, and in other generalized linear or nonlinear models).\n",
    "Multilevel models and marginal models estimate the same population\n",
    "target, but represent this target in different ways, and utilize\n",
    "different estimation procedures.\n",
    "\n",
    "A multilevel model is usually expressed in terms of *random effects*.\n",
    "These are variables that we do not observe, but that we can\n",
    "nevertheless incorporate into a statistical model.  We cannot get into\n",
    "all of the technical details here, but it is important to understand\n",
    "that while these random effects are not observed, their presence can\n",
    "be inferred through the data, as long as each random effect is modeled as\n",
    "influencing at least two observations.\n",
    "\n",
    "In the present setting, we are focusing only on dependence that arises\n",
    "through a single level of clustering.  To put this in the context of\n",
    "multilevel modeling, we can imagine that each cluster has a random\n",
    "effect that is shared by all observations in that cluster.  For\n",
    "example, if SBP tends to be around 0.5 units higher in one cluster,\n",
    "then the random effect for that cluster would be 0.5, and it would add\n",
    "to the predicted SBP for every observation in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>256.6952</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>     <td>Log-Likelihood:</td>   <td>-21409.8702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>92.173</td>   <td>1.402</td>  <td>65.752</td> <td>0.000</td> <td>89.426</td> <td>94.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>  <td>3.650</td>   <td>0.452</td>   <td>8.084</td> <td>0.000</td>  <td>2.765</td>  <td>4.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>   <td>0.153</td>   <td>0.887</td>   <td>0.172</td> <td>0.863</td> <td>-1.586</td>  <td>1.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>  <td>-2.238</td>   <td>0.758</td>  <td>-2.954</td> <td>0.003</td> <td>-3.723</td> <td>-0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>   <td>3.098</td>   <td>0.836</td>   <td>3.707</td> <td>0.000</td>  <td>1.460</td>  <td>4.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>  <td>-0.439</td>   <td>0.878</td>  <td>-0.500</td> <td>0.617</td> <td>-2.161</td>  <td>1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIDAGEYR</th>           <td>0.474</td>   <td>0.013</td>  <td>36.482</td> <td>0.000</td>  <td>0.449</td>  <td>0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>             <td>0.280</td>   <td>0.033</td>   <td>8.404</td> <td>0.000</td>  <td>0.215</td>  <td>0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group Var</th>          <td>3.615</td>   <td>0.085</td>     <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table><br/>\n"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{Mixed Linear Model Regression Results}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{llll}\n",
       "\\hline\n",
       "Model:            & MixedLM & Dependent Variable: & BPXSY1       \\\\\n",
       "No. Observations: & 5102    & Method:             & REML         \\\\\n",
       "No. Groups:       & 30      & Scale:              & 256.6952     \\\\\n",
       "Min. group size:  & 106     & Log-Likelihood:     & -21409.8702  \\\\\n",
       "Max. group size:  & 226     & Converged:          & Yes          \\\\\n",
       "Mean group size:  & 170.1   &                     &              \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\n",
       "\\begin{center}\n",
       "\\begin{tabular}{lrrrrrr}\n",
       "\\hline\n",
       "                  &  Coef. & Std.Err. &      z & P$> |$z$|$ & [0.025 & 0.975]  \\\\\n",
       "\\hline\n",
       "Intercept         & 92.173 &    1.402 & 65.752 &       0.000 & 89.426 & 94.921  \\\\\n",
       "RIAGENDRx[T.Male] &  3.650 &    0.452 &  8.084 &       0.000 &  2.765 &  4.535  \\\\\n",
       "C(RIDRETH1)[T.2]  &  0.153 &    0.887 &  0.172 &       0.863 & -1.586 &  1.891  \\\\\n",
       "C(RIDRETH1)[T.3]  & -2.238 &    0.758 & -2.954 &       0.003 & -3.723 & -0.753  \\\\\n",
       "C(RIDRETH1)[T.4]  &  3.098 &    0.836 &  3.707 &       0.000 &  1.460 &  4.737  \\\\\n",
       "C(RIDRETH1)[T.5]  & -0.439 &    0.878 & -0.500 &       0.617 & -2.161 &  1.282  \\\\\n",
       "RIDAGEYR          &  0.474 &    0.013 & 36.482 &       0.000 &  0.449 &  0.500  \\\\\n",
       "BMXBMI            &  0.280 &    0.033 &  8.404 &       0.000 &  0.215 &  0.346  \\\\\n",
       "group Var         &  3.615 &    0.085 &        &             &        &         \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "           Mixed Linear Model Regression Results\n",
       "============================================================\n",
       "Model:             MixedLM  Dependent Variable:  BPXSY1     \n",
       "No. Observations:  5102     Method:              REML       \n",
       "No. Groups:        30       Scale:               256.6952   \n",
       "Min. group size:   106      Log-Likelihood:      -21409.8702\n",
       "Max. group size:   226      Converged:           Yes        \n",
       "Mean group size:   170.1                                    \n",
       "------------------------------------------------------------\n",
       "                  Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
       "------------------------------------------------------------\n",
       "Intercept         92.173    1.402 65.752 0.000 89.426 94.921\n",
       "RIAGENDRx[T.Male]  3.650    0.452  8.084 0.000  2.765  4.535\n",
       "C(RIDRETH1)[T.2]   0.153    0.887  0.172 0.863 -1.586  1.891\n",
       "C(RIDRETH1)[T.3]  -2.238    0.758 -2.954 0.003 -3.723 -0.753\n",
       "C(RIDRETH1)[T.4]   3.098    0.836  3.707 0.000  1.460  4.737\n",
       "C(RIDRETH1)[T.5]  -0.439    0.878 -0.500 0.617 -2.161  1.282\n",
       "RIDAGEYR           0.474    0.013 36.482 0.000  0.449  0.500\n",
       "BMXBMI             0.280    0.033  8.404 0.000  0.215  0.346\n",
       "group Var          3.615    0.085                           \n",
       "============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a multilevel (mixed effects) model to handle dependent data\n",
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           groups=\"group\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"variance structure parameters\" are what distinguish a mixed model from a marginal model.  Here we only have one such parameter, which is the variance for groups, estimated to be 3.615.  This means that if we were to choose two groups at random, their random effects would differ on average by around 2.69 (this is calculated as the square root of $2\\cdot 3.615$).  This is a sizable shift, comparable to the difference between females and males, or to around 6 years of aging.\n",
    "\n",
    "We have seen here that it least in this setting, the mixed modeling procedure accommodates dependence in the data, provides rigorous estimates of the strength of this dependence, and accounts for the dependence in both estimation and inference for the regression parameters.  In this sense, the multilevel model has the same desirable properties as GEE (at least in this setting).  In fact, each of these two methods is very useful and widely utilized.  There are some settings where either GEE or multilevel modeling can be argued to have an advantage, but neither uniformly dominates the other.\n",
    "\n",
    "Multilevel models can also be used to estimate ICC values.  In the case of a model with one level, which is what we have here, the ICC is the variance of the grouping variable (3.615) divided by the sum of the variance of the grouping variable and the unexplained variance (256.7).  Note that the unexplained variance is in upper part of the output, labeled *scale*.  This ratio is around 0.014, which is very similar to the estimated ICC obtained using GEE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted random effects\n",
    "\n",
    "While the actual random effects in a multilevel model are never observable, we can predict them from the data.  The predicted random effects are commonly known as *BLUPs*, for \"Best Linear Unbiased Predictors\".\n",
    "\n",
    "Examing the BLUPs is sometimes useful, although the emphasis in multilevel regression usually lies with the structural parameters that underlie the random effects, and not the random effects themselves.  In the NHANES analysis, for example, we could use the predicted random effects to quantify the uniqueness of each county relative to the mean.\n",
    "\n",
    "The predicted random effects for the 30 groups (MVUs) in this analysis are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1191: group   -1.630976\n",
       " dtype: float64,\n",
       " 1192: group   -0.086162\n",
       " dtype: float64,\n",
       " 1201: group   -2.042661\n",
       " dtype: float64,\n",
       " 1202: group   -0.147472\n",
       " dtype: float64,\n",
       " 1211: group    0.280623\n",
       " dtype: float64,\n",
       " 1212: group    1.580732\n",
       " dtype: float64,\n",
       " 1221: group    0.283347\n",
       " dtype: float64,\n",
       " 1222: group    0.131512\n",
       " dtype: float64,\n",
       " 1231: group   -2.038171\n",
       " dtype: float64,\n",
       " 1232: group    0.617651\n",
       " dtype: float64,\n",
       " 1241: group    2.878488\n",
       " dtype: float64,\n",
       " 1242: group   -0.519364\n",
       " dtype: float64,\n",
       " 1251: group    2.064967\n",
       " dtype: float64,\n",
       " 1252: group    1.521281\n",
       " dtype: float64,\n",
       " 1261: group   -1.261975\n",
       " dtype: float64,\n",
       " 1262: group    0.980846\n",
       " dtype: float64,\n",
       " 1271: group    0.118031\n",
       " dtype: float64,\n",
       " 1272: group   -0.128397\n",
       " dtype: float64,\n",
       " 1281: group   -0.384862\n",
       " dtype: float64,\n",
       " 1282: group   -3.582111\n",
       " dtype: float64,\n",
       " 1291: group   -3.271017\n",
       " dtype: float64,\n",
       " 1292: group   -0.829538\n",
       " dtype: float64,\n",
       " 1301: group   -0.884171\n",
       " dtype: float64,\n",
       " 1302: group    2.790657\n",
       " dtype: float64,\n",
       " 1311: group   -0.585201\n",
       " dtype: float64,\n",
       " 1312: group    1.198291\n",
       " dtype: float64,\n",
       " 1321: group   -0.195692\n",
       " dtype: float64,\n",
       " 1322: group    1.955515\n",
       " dtype: float64,\n",
       " 1331: group   -0.305559\n",
       " dtype: float64,\n",
       " 1332: group    1.491389\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.random_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examing the BLUPs, we see for example, that cluster 1241 has an unusually high BLUP, and cluster 1282 has an unusually low BLUP.  These values are obtained after adjusting for the covariates in the model, and hence are presumably driven by characteristics of these clusters that are not reflected in the covariates.  Evidently, there is some characteristic of cluster 1241 that would explain a tendency for people in that cluster to have higher blood pressure, but this characteristic is not among our covariates (ethnicity, gender, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random slopes\n",
    "\n",
    "Multilevel modeling is a broad framework that allows many different types of models to be specified and fit.  Here we are primarily focusing on the \"random intercept models\", that allow the data in each cluster to be shifted by a common amount, in order to account for stable confounders within clusters.  Above we found evidence that such clustering (non-independence) is present in the NHANES blood pressure data.  Next we consider a more subtle form of cluster effect, in which the slope for a specific covariate varies from cluster to cluster.  This is called a *random slopes model*.  To demonstrate, below we fit a model in which SBP has cluster-specific intercepts, and cluster-specific slopes for the age covariate.  That is, we ask whether the rate at which blood pressure increases with age might differ from one cluster to the next.\n",
    "\n",
    "We fit two variations on this model.  In the first model, the cluster-specific intercepts and slopes are independent random variables.  That is, a cluster with unusually high SBP is no more or less likely to have unusually rapid increase of SBP with age.  Note that when working with random slopes, it is usually advisable to center any covariate which has a random slope.  This does not change the fundamental interpretation of the model, but it does often result in models that converge faster and more robustly.  Here we center within each cluster, although it is also common to center in the\n",
    "entire dataset, rather than centering separately by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/lsa-kshedden/statsmodels/statsmodels/statsmodels/regression/mixed_linear_model.py:2238: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>263.7323</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>     <td>Log-Likelihood:</td>   <td>-21469.9240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>115.207</td>   <td>1.209</td>  <td>95.265</td> <td>0.000</td> <td>112.836</td> <td>117.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>  <td>3.643</td>    <td>0.457</td>   <td>7.962</td> <td>0.000</td>  <td>2.746</td>   <td>4.539</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>   <td>1.167</td>    <td>0.827</td>   <td>1.412</td> <td>0.158</td> <td>-0.453</td>   <td>2.787</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>  <td>-1.659</td>    <td>0.679</td>  <td>-2.444</td> <td>0.015</td> <td>-2.989</td>  <td>-0.328</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>   <td>3.610</td>    <td>0.739</td>   <td>4.884</td> <td>0.000</td>  <td>2.161</td>   <td>5.058</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>  <td>-1.208</td>    <td>0.816</td>  <td>-1.480</td> <td>0.139</td> <td>-2.807</td>   <td>0.392</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen</th>            <td>0.467</td>    <td>0.018</td>  <td>26.235</td> <td>0.000</td>  <td>0.432</td>   <td>0.502</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>             <td>0.288</td>    <td>0.034</td>   <td>8.574</td> <td>0.000</td>  <td>0.222</td>   <td>0.353</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen Var</th>        <td>0.004</td>    <td>0.000</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "</table><br/>\n"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{Mixed Linear Model Regression Results}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{llll}\n",
       "\\hline\n",
       "Model:            & MixedLM & Dependent Variable: & BPXSY1       \\\\\n",
       "No. Observations: & 5102    & Method:             & REML         \\\\\n",
       "No. Groups:       & 30      & Scale:              & 263.7323     \\\\\n",
       "Min. group size:  & 106     & Log-Likelihood:     & -21469.9240  \\\\\n",
       "Max. group size:  & 226     & Converged:          & Yes          \\\\\n",
       "Mean group size:  & 170.1   &                     &              \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\n",
       "\\begin{center}\n",
       "\\begin{tabular}{lrrrrrr}\n",
       "\\hline\n",
       "                  &   Coef. & Std.Err. &      z & P$> |$z$|$ &  [0.025 &  0.975]  \\\\\n",
       "\\hline\n",
       "Intercept         & 115.207 &    1.209 & 95.265 &       0.000 & 112.836 & 117.577  \\\\\n",
       "RIAGENDRx[T.Male] &   3.643 &    0.457 &  7.962 &       0.000 &   2.746 &   4.539  \\\\\n",
       "C(RIDRETH1)[T.2]  &   1.167 &    0.827 &  1.412 &       0.158 &  -0.453 &   2.787  \\\\\n",
       "C(RIDRETH1)[T.3]  &  -1.659 &    0.679 & -2.444 &       0.015 &  -2.989 &  -0.328  \\\\\n",
       "C(RIDRETH1)[T.4]  &   3.610 &    0.739 &  4.884 &       0.000 &   2.161 &   5.058  \\\\\n",
       "C(RIDRETH1)[T.5]  &  -1.208 &    0.816 & -1.480 &       0.139 &  -2.807 &   0.392  \\\\\n",
       "age\\_cen          &   0.467 &    0.018 & 26.235 &       0.000 &   0.432 &   0.502  \\\\\n",
       "BMXBMI            &   0.288 &    0.034 &  8.574 &       0.000 &   0.222 &   0.353  \\\\\n",
       "age\\_cen Var      &   0.004 &    0.000 &        &             &         &          \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "             Mixed Linear Model Regression Results\n",
       "===============================================================\n",
       "Model:              MixedLM   Dependent Variable:   BPXSY1     \n",
       "No. Observations:   5102      Method:               REML       \n",
       "No. Groups:         30        Scale:                263.7323   \n",
       "Min. group size:    106       Log-Likelihood:       -21469.9240\n",
       "Max. group size:    226       Converged:            Yes        \n",
       "Mean group size:    170.1                                      \n",
       "---------------------------------------------------------------\n",
       "                   Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
       "---------------------------------------------------------------\n",
       "Intercept         115.207    1.209 95.265 0.000 112.836 117.577\n",
       "RIAGENDRx[T.Male]   3.643    0.457  7.962 0.000   2.746   4.539\n",
       "C(RIDRETH1)[T.2]    1.167    0.827  1.412 0.158  -0.453   2.787\n",
       "C(RIDRETH1)[T.3]   -1.659    0.679 -2.444 0.015  -2.989  -0.328\n",
       "C(RIDRETH1)[T.4]    3.610    0.739  4.884 0.000   2.161   5.058\n",
       "C(RIDRETH1)[T.5]   -1.208    0.816 -1.480 0.139  -2.807   0.392\n",
       "age_cen             0.467    0.018 26.235 0.000   0.432   0.502\n",
       "BMXBMI              0.288    0.034  8.574 0.000   0.222   0.353\n",
       "age_cen Var         0.004    0.000                             \n",
       "===============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da[\"age_cen\"] = da.groupby(\"group\").RIDAGEYR.transform(lambda x: x - x.mean())\n",
    "\n",
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ age_cen + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           groups=\"group\", vc_formula={\"age_cen\": \"0+age_cen\"}, data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the estimated variance for random age slopes is 0.004, which translates to a standard deviation of 0.06.  That is, from one cluster to another, the age slopes fluctuate by $\\pm 0.06-0.12$ (1-2 standard deviations).  These cluster-specific fluctuations are added/subtracted from the fixed effect for age, which is 0.467.  Thus, in some clusters SBP may increase by around $0.467 + 0.06 = 0.527$ mm Hg per year, while in other clusters SBP may increase by only around $0.467 - 0.06 = 0.407$ mm Hg per year.  Note also that the fitting algorithm produces a warning that the estimated variance parameter is close to the boundary.  In this case, however, the algorithm seems to have converged to a point just short of the boundary.\n",
    "\n",
    "Next, we fit a model in which the cluster-specific intercepts and slopes are allowed to be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/lsa-kshedden/statsmodels/statsmodels/statsmodels/regression/mixed_linear_model.py:2238: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>255.4451</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>     <td>Log-Likelihood:</td>   <td>-21413.6193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>            <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>115.467</td>   <td>1.340</td>  <td>86.173</td> <td>0.000</td> <td>112.840</td> <td>118.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>    <td>3.662</td>    <td>0.451</td>   <td>8.121</td> <td>0.000</td>  <td>2.778</td>   <td>4.546</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>     <td>0.023</td>    <td>0.898</td>   <td>0.025</td> <td>0.980</td> <td>-1.738</td>   <td>1.783</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>    <td>-2.251</td>    <td>0.778</td>  <td>-2.893</td> <td>0.004</td> <td>-3.775</td>  <td>-0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>     <td>3.011</td>    <td>0.854</td>   <td>3.524</td> <td>0.000</td>  <td>1.336</td>   <td>4.686</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>    <td>-0.585</td>    <td>0.893</td>  <td>-0.655</td> <td>0.512</td> <td>-2.336</td>   <td>1.165</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen</th>              <td>0.466</td>    <td>0.018</td>  <td>26.286</td> <td>0.000</td>  <td>0.431</td>   <td>0.501</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>               <td>0.283</td>    <td>0.033</td>   <td>8.497</td> <td>0.000</td>  <td>0.218</td>   <td>0.349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group Var</th>            <td>8.655</td>    <td>0.169</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group x age_cen Cov</th>  <td>0.119</td>    <td>0.004</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen Var</th>          <td>0.004</td>    <td>0.000</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "</table><br/>\n"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{Mixed Linear Model Regression Results}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{llll}\n",
       "\\hline\n",
       "Model:            & MixedLM & Dependent Variable: & BPXSY1       \\\\\n",
       "No. Observations: & 5102    & Method:             & REML         \\\\\n",
       "No. Groups:       & 30      & Scale:              & 255.4451     \\\\\n",
       "Min. group size:  & 106     & Log-Likelihood:     & -21413.6193  \\\\\n",
       "Max. group size:  & 226     & Converged:          & Yes          \\\\\n",
       "Mean group size:  & 170.1   &                     &              \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\n",
       "\\begin{center}\n",
       "\\begin{tabular}{lrrrrrr}\n",
       "\\hline\n",
       "                     &   Coef. & Std.Err. &      z & P$> |$z$|$ &  [0.025 &  0.975]  \\\\\n",
       "\\hline\n",
       "Intercept            & 115.467 &    1.340 & 86.173 &       0.000 & 112.840 & 118.093  \\\\\n",
       "RIAGENDRx[T.Male]    &   3.662 &    0.451 &  8.121 &       0.000 &   2.778 &   4.546  \\\\\n",
       "C(RIDRETH1)[T.2]     &   0.023 &    0.898 &  0.025 &       0.980 &  -1.738 &   1.783  \\\\\n",
       "C(RIDRETH1)[T.3]     &  -2.251 &    0.778 & -2.893 &       0.004 &  -3.775 &  -0.726  \\\\\n",
       "C(RIDRETH1)[T.4]     &   3.011 &    0.854 &  3.524 &       0.000 &   1.336 &   4.686  \\\\\n",
       "C(RIDRETH1)[T.5]     &  -0.585 &    0.893 & -0.655 &       0.512 &  -2.336 &   1.165  \\\\\n",
       "age\\_cen             &   0.466 &    0.018 & 26.286 &       0.000 &   0.431 &   0.501  \\\\\n",
       "BMXBMI               &   0.283 &    0.033 &  8.497 &       0.000 &   0.218 &   0.349  \\\\\n",
       "group Var            &   8.655 &    0.169 &        &             &         &          \\\\\n",
       "group x age\\_cen Cov &   0.119 &    0.004 &        &             &         &          \\\\\n",
       "age\\_cen Var         &   0.004 &    0.000 &        &             &         &          \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "              Mixed Linear Model Regression Results\n",
       "=================================================================\n",
       "Model:                MixedLM   Dependent Variable:   BPXSY1     \n",
       "No. Observations:     5102      Method:               REML       \n",
       "No. Groups:           30        Scale:                255.4451   \n",
       "Min. group size:      106       Log-Likelihood:       -21413.6193\n",
       "Max. group size:      226       Converged:            Yes        \n",
       "Mean group size:      170.1                                      \n",
       "-----------------------------------------------------------------\n",
       "                     Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Intercept           115.467    1.340 86.173 0.000 112.840 118.093\n",
       "RIAGENDRx[T.Male]     3.662    0.451  8.121 0.000   2.778   4.546\n",
       "C(RIDRETH1)[T.2]      0.023    0.898  0.025 0.980  -1.738   1.783\n",
       "C(RIDRETH1)[T.3]     -2.251    0.778 -2.893 0.004  -3.775  -0.726\n",
       "C(RIDRETH1)[T.4]      3.011    0.854  3.524 0.000   1.336   4.686\n",
       "C(RIDRETH1)[T.5]     -0.585    0.893 -0.655 0.512  -2.336   1.165\n",
       "age_cen               0.466    0.018 26.286 0.000   0.431   0.501\n",
       "BMXBMI                0.283    0.033  8.497 0.000   0.218   0.349\n",
       "group Var             8.655    0.169                             \n",
       "group x age_cen Cov   0.119    0.004                             \n",
       "age_cen Var           0.004    0.000                             \n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ age_cen + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "           groups=\"group\", re_formula=\"1+age_cen\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we get a warning that the parameter estimates fall close to the boundary. The estimated correlation coefficient between random slopes and random intercepts is estimated to be $0.119/\\sqrt{8.655\\cdot 0.004}$, which is around $0.64$.  This indicates that the clusters with unusually high average SBP also tend to have SBP increasing faster with age.  Note\n",
    "however that these structural parameters are only estimates, and due to the variance parameter falling close to the boundary, the estimates may not be particularly precise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
