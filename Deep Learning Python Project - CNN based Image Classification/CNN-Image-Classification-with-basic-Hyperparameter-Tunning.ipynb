{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image Classification Using CNN with the CIFAR-10 Dataset\n",
        "using **basic Hyperparameter Tunning**"
      ],
      "metadata": {
        "id": "LqufFCSz4plI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_tuner"
      ],
      "metadata": {
        "id": "3zIWF80K3oBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlL4bP7-jgvD"
      },
      "outputs": [],
      "source": [
        "# Step 1: Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Loading and preprocessing the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Step 3: Defining the class names for CIFAR-10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Step 4: Define a function to build the model.\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Tune the number of convolutional layers (1, 2 or 3)\n",
        "    for i in range(hp.Int('conv_layers', 1, 3)):\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv2D(\n",
        "                filters=hp.Int('filters_' + str(i), min_value=32, max_value=128, step=16),\n",
        "                kernel_size=3,\n",
        "                activation='relu',\n",
        "                input_shape=(32, 32, 3)))\n",
        "        else:\n",
        "            model.add(layers.Conv2D(\n",
        "                filters=hp.Int('filters_' + str(i), min_value=64, max_value=128, step=16),\n",
        "                kernel_size=3,\n",
        "                activation='relu',\n",
        "                padding='same'))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Tune the number of dense layers (1, 2, or 3)\n",
        "    for i in range(hp.Int('dense_layers', 1, 3)):\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=16),\n",
        "            activation='relu'))\n",
        "\n",
        "        # Tune the dropout rate\n",
        "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # The last dense layer with 10 output units (for 10 classes)\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Choose an optimizer and learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Step 5: Define the Tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='cifar10_tunning'\n",
        ")\n",
        "\n",
        "# Step 6: Perform the Hyperparameter search\n",
        "tuner.search(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Step 7: Get the best Hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Step 8: Build the model with the best Hyperparameters and train it\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Step 9: Plotting training & validation accuracy and loss values\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ]
}